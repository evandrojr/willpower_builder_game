{
  "name": "simple-html-tokenizer",
  "version": "0.1.1",
  "license": "MIT",
  "description": "Simple HTML Tokenizer is a lightweight JavaScript library that can be used to tokenize the kind of HTML normally found in templates.",
  "keywords": [
    "html",
    "tokenizer"
  ],
  "repository": {
    "type": "git",
    "url": "https://github.com/tildeio/simple-html-tokenizer.git"
  },
  "main": "dist/simple-html-tokenizer.js",
  "scripts": {
    "build": "compile-modules convert -I lib -f bundle -o dist/simple-html-tokenizer.js simple-html-tokenizer.umd.js",
    "prepublish": "npm run build",
    "test": "npm run build && testem ci"
  },
  "devDependencies": {
    "es6-module-transpiler": "^0.9.5",
    "qunit-extras": "^1.3.0",
    "qunitjs": "^1.16.0",
    "testem": "^0.6.23"
  },
  "readme": "# About\n\nSimple HTML Tokenizer is a lightweight JavaScript library that can be\nused to tokenize the kind of HTML normally found in templates. It can be\nused to preprocess templates to change the behavior of some template\nelement depending upon whether the template element was found in an\nattribute or text.\n\nIt is not a full HTML5 tokenizer. It focuses on the kind of HTML that is\nused in templates: content designed to be inserted into the `<body>`\nand without `<script>` tags.\n\nIn particular, Simple HTML Tokenizer does not handle many states from\nthe [HTML5 Tokenizer Specification][1]:\n\n* Any states involving `CDATA` or `RCDATA`\n* Any states involving `<script>`\n* Any states involving `<DOCTYPE>`\n* The bogus comment state\n\nIt also passes through character references, instead of trying to\ntokenize and process them, because the preprocessed templates will\nultimately be parsed by a real browser context.\n\nAt the moment, there are some error states specified by the tokenizer\nspec that are not handled by Simple HTML Tokenizer. Ultimately, I plan\nto support all error states, as well as provide information about\ntokenizer errors in debug mode.\n\n[1]: http://www.whatwg.org/specs/web-apps/current-work/multipage/tokenization.html\n\n# Usage\n\nYou can tokenize HTML:\n\n```js\nvar tokens = HTML5Tokenizer.tokenize(\"<div id='foo' href=bar class=\\\"bat\\\">\");\n\nvar token = tokens[0];\ntoken.tagName     //=> \"div\"\ntoken.attributes  //=> [[\"id\", \"foo\"], [\"href\", \"bar\"], [\"class\", \"bat\"]]\ntoken.selfClosing //=> false\n```\n\nAnd then generate HTML back out from the tokens:\n\n```js\nvar tokens = HTML5Tokenizer.tokenize(\"<div id='foo' href=bar class=\\\"bat\\\">\");\n\nHTML5Tokenizer.generate(tokens) //=> '<div id=\"foo\" href=\"bar\" class=\"bat\">'\n```\n\nIn practice, you would probably want some transformations on the\ngenerated output, so you can register hooks to generate a tag or just\nthe attribute portion.\n\n```js\nHTML5Tokenizer.configure('generateTag', function(tag) {\n  // takes a tag token (see above) and returns a string\n});\n\nHTML5Tokenizer.configure('generateAttributes', function(attributes) {\n  // takes just the attributes array and returns a string for the\n  // attributes part to be inserted into the tag.\n});\n```\n\n## Building and running the tests\n\nBefore running the build or tests make sure you have grunt and bower installed globally.\n\n```bash\nnpm install -g grunt-cli\nnpm install -g bower\n```\n\nNext install the package dependencies:\n\n```bash\nnpm install\nbower install\n```\n\nGrunt commands:\n\n`grunt dist` - Build dist (commonjs, amd, globals)\n`grunt test` - Run tests in node\n`grunt server` - Run tests in browser at <http://localhost:4200>\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/tildeio/simple-html-tokenizer/issues"
  },
  "_id": "simple-html-tokenizer@0.1.1",
  "_from": "simple-html-tokenizer@^0.1.1"
}
